{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33gMAp3zdrGO"
      },
      "source": [
        "Authenticate with Google Cloud CLI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uoqoHCopd0Gw",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gcloud init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVVQEgukKD-"
      },
      "source": [
        "Create credentials file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fiGUh4BHkLuL",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG8XAiz7eUDa"
      },
      "source": [
        "Create resources on Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cK9iBQxN0nFh",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Google Cloud Storage Temporary Files\n",
        "!gsutil mb gs://dataflow_temp_storage_<name>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pclhGFzuoJhS",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Destination Dataset (Data Warehouse)\n",
        "!bq --location=US mk --dataset \"<project_id>:nyctaxi\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pubsub subscription to pull messages from streaming source\n",
        "!gcloud pubsub subscriptions create \"taxirides\" --topic=\"projects/pubsub-public-data/topics/taxirides-realtime\""
      ],
      "metadata": {
        "id": "BND0w0XtKNrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh13gsWPf_Bx"
      },
      "source": [
        "Install Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM3rqzvyhPg-"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install fsspec\n",
        "!pip install gcsfs\n",
        "!pip install 'apache-beam[gcp]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctprN-zshqVx"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5A-LDcfhsag"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import apache_beam as beam\n",
        "from datetime import date\n",
        "from apache_beam.io.gcp.pubsub import ReadFromPubSub\n",
        "from apache_beam.io.gcp.bigquery import WriteToBigQuery\n",
        "from apache_beam.options.pipeline_options import PipelineOptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va220jUrh5km"
      },
      "source": [
        "Initialising variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9PtmxS9h8Td"
      },
      "outputs": [],
      "source": [
        "custom_gcs_temp_location = \"gs://dataflow_temp_storage_<name>\"\n",
        "subscription_name = \"projects/<project_id>/subscriptions/taxirides\"\n",
        "output_table = \"<project_id>:nyctaxi.taxirides-realtime\"\n",
        "schema = \"\"\"ride_id:STRING,\n",
        "point_idx:INTEGER,\n",
        "latitude:FLOAT64,\n",
        "longitude:FLOAT64,\n",
        "timestamp:TIMESTAMP,\n",
        "meter_reading:FLOAT64,\n",
        "meter_increment:FLOAT64,\n",
        "ride_status:STRING,\n",
        "passenger_count:INTEGER\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVFLCehWij_K"
      },
      "source": [
        "Data processing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r6lPJsMiohJ"
      },
      "outputs": [],
      "source": [
        "def process_columns(element):\n",
        "    data = element.decode(\"utf-8\")\n",
        "    data = json.loads(data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00-nY39SitRi"
      },
      "source": [
        "Running apache beam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "beam_options = PipelineOptions(\n",
        "    streaming=True,\n",
        "    runner='DataflowRunner',\n",
        "    project='<project_id>',\n",
        "    job_name='<job_name>',\n",
        "    staging_location=\"gs://dataflow_temp_storage_<name>/staging\",\n",
        "    temp_location='gs://dataflow_temp_storage_<name>/temp',\n",
        "    template_location=\"gs://dataflow_temp_storage_<name>/templates/streamingpipeline\",\n",
        "    region='us-central1')\n",
        "\n",
        "with beam.Pipeline(options=beam_options) as pipeline:\n",
        "\n",
        "    input_data = pipeline | \"Read from Pub/Sub\" >> ReadFromPubSub(subscription=subscription_name)\n",
        "\n",
        "    processed_data = input_data | 'ProcessColumns' >> beam.Map(process_columns)\n",
        "\n",
        "    processed_data  | 'WriteToBigQuery' >> WriteToBigQuery(\n",
        "         table=output_table,\n",
        "         schema=schema,\n",
        "         custom_gcs_temp_location=custom_gcs_temp_location,\n",
        "         create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
        "         write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)"
      ],
      "metadata": {
        "id": "tYIT-Yt_C3_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add all the code in a python file and create Dataflow template"
      ],
      "metadata": {
        "id": "RH44NLUDxVHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m streamingpipeline \\\n",
        "  --runner DataflowRunner \\\n",
        "  --project <project_id> \\\n",
        "  --staging_location gs://dataflow_temp_storage_<name>/staging \\\n",
        "  --temp_location gs://dataflow_temp_storage_<name>/temp \\\n",
        "  --template_location gs://dataflow_temp_storage_<name>/templates/dataproc-job \\\n",
        "  --region us-central1 \\"
      ],
      "metadata": {
        "id": "JjgMMQ6r8r6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to console and enable Dataflow, Data Pipeline, Cloud Scheduler API\n",
        "Run Dataflow job."
      ],
      "metadata": {
        "id": "bq1RGlMmlfbN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l2ssDhtb4eY"
      },
      "outputs": [],
      "source": [
        "!gcloud dataflow jobs run tripdata --gcs-location gs://dataflow_temp_storage_909090/templates/streamingpipeline --region us-central1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}